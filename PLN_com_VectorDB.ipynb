{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLN com Embedding em VectorDB\n",
    "\n",
    "# Ambiente Virtual (venv): ambpln1 (C:\\IA-Estudos\\PLN\\ambpln1)\n",
    "\n",
    "# Bibliotecas para NLP\n",
    "\n",
    "# Para chunks e embeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # pip install langchain\n",
    "from sentence_transformers import SentenceTransformer # pip install sentence_transformers\n",
    "\n",
    "# Para leitura de PDF\n",
    "import pdfplumber # pip install pdfplumber\n",
    "\n",
    "# Para tratamento de texto\n",
    "import re\n",
    "import spacy # python -m spacy download pt_core_news_sm\n",
    "import nltk # pip install nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Baixando dados do NLTK necessários (se ainda não tiver)\n",
    "# nltk.download('stopwords') # rodar apenas uma vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banco de Dados Vetorial (Vector Database)\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando PDFs\n",
    "\n",
    "def ler_pdf(caminho_pdf):\n",
    "    \n",
    "    leitor_pdf = pdfplumber.open(caminho_pdf)\n",
    "    # page = leitor_pdf.pages[0]\n",
    "    texto = \"\"\n",
    "    for pagina in range(len(leitor_pdf.pages)):\n",
    "        texto += leitor_pdf.pages[pagina].extract_text()        \n",
    "\n",
    "    texto = texto.replace(\"\\n\", \" \")\n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do texto em caracteres: 1741\n",
      "Chapeuzinho Vermelho e o Lobo Mau Era uma vez uma menina chamada Chapeuzinho Vermelho. Um dia, sua mãe pediu-lhe para levar uma cesta com doces para a vovó doentinha. A mãe, porém, advertiu a menina: “Não entre na floresta nem converse com estranhos”. Mas Chapeuzinho era muito distraída e acabou saindo da estradinha e entrando na floresta. Um lobo então surgiu de entre as árvores, quis saber se a menina estava perdida. Ela disse que não e falou para onde estava indo. E o lobo aconselhou-a a pegar o caminho das flores, pois era mais curto. Que lobo mentiroso! Era o caminho mais longo... Assim, após enganar a menina, o lobo colocou seu plano em prática e chegou primeiro à casa da vovó, devorando a vovó da Chapeuzinho. Depois de devorar a vovó, o lobo decidiu enganar mais uma vez a menina, então colocou a touca da velhinha, vestiu sua roupa, deitou-se na cama e se cobriu com um cobertor. Quando a menina chegou, percebeu que a “vovó” estava meio diferente. — Que orelhas grandes a senhora tem, vovó. — São para te ouvir melhor, querida. — Que olhos grandes a senhora tem, vovó. — São para te ver melhor, meu chuchu. — Que mãos grandes a senhora tem, vovozinha. — São para te abraçar, doçura. — E que boca grande a senhora tem, vovozinha. — Ah, é para te devorar!!!! Após dizer isso, o lobo devorou Chapeuzinho Vermelho. Então, de barriga cheia, o bicho dormiu e até roncou. Mas um caçador ouviu os roncos de lobo e percebeu que a porta da casa da vovó estava aberta. Entrou na casa, viu o lobo dormindo sobre a cama e não perdeu tempo. O caçador abriu a barriga do bicho e tirou vovó e netinha lá de dentro. Depois, encheu a barriga do lobo com pedras, costurou tudo e afundou o bicho em um rio, para ele nunca mais fazer maldades.\n"
     ]
    }
   ],
   "source": [
    "# Carregar os documentos do PDF\n",
    "arquivo_pdf = \"C:/Users/Douglas/Desktop/prova/chapeuzinho.pdf\"\n",
    "texto_pdf = ler_pdf(arquivo_pdf)\n",
    "\n",
    "# Tamanho do texto\n",
    "print(\"Tamanho do texto em caracteres:\",len(texto_pdf))\n",
    "\n",
    "# Arquivo PDF original\n",
    "print(texto_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLN\n",
    "\n",
    "# Carregar o modelo de linguagem do spaCy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "# Definir stopwords\n",
    "api_stop_words = set(stopwords.words('portuguese'))\n",
    "minhas_stop_words = {'a','e','i','o', 'u'}\n",
    "stop_words = api_stop_words | minhas_stop_words\n",
    "\n",
    "# Função para fazer o tratamento de linguagem natural usando spaCy\n",
    "def tratamento_pln(texto):\n",
    "\n",
    "    # 1. Normalização: Colocar o texto em minúsculas\n",
    "    texto = texto.lower()\n",
    "\n",
    "    # 2. Remoção de números, pontuações e caracteres especiais\n",
    "    texto = re.sub(r'[^a-zA-Záéíóú\\s]', '', texto) # na expressão regular estão as exceções\n",
    "\n",
    "    # 3. Tokenização com spaCy\n",
    "    doc = nlp(texto)\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    # 4. Remoção de stopwords, remoção de pontuação\n",
    "    #    e Lematização (clean_tokens = tokens lematizados e sem stopwords)\n",
    "    clean_tokens = [token.lemma_ for token in doc if token.text not in stop_words and not token.is_punct]\n",
    " \n",
    "    # 5. Juntar tokens lematizados de volta em uma string\n",
    "    clean_text = ' '.join(clean_tokens)\n",
    "\n",
    "    return clean_text\n",
    "    #return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tamanho do conjunto stop_words:\",len(stop_words),\"\\nStop_words ordenadas: \\n\",sorted(list(stop_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamada de PLN\n",
    "texto_pdf_tratado = tratamento_pln(texto_pdf)\n",
    "\n",
    "# Tamanho do texto\n",
    "print(\"Tamanho do texto em caracteres:\",len(texto_pdf))\n",
    "\n",
    "# Arquivo PDF tratado\n",
    "print(texto_pdf_tratado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os documentos\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=40, chunk_overlap=10)\n",
    "chunks = text_splitter.split_text(texto_pdf_tratado)\n",
    "print(chunks, len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo de Embeddings bem como gerar os Embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(chunks)\n",
    "\n",
    "# Gerando IDs automaticamente\n",
    "uids = [f\"doc_{i}\" for i in range(len(chunks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o banco de dados\n",
    "client = chromadb.Client()\n",
    "#client.delete_collection(\"lobomau\")\n",
    "collection = client.create_collection(name=\"lobomau\")\n",
    "#collection = client.get_collection(name=\"lobomau\")\n",
    "\n",
    "# Adicionar os documentos ao banco de dados\n",
    "collection.add(documents=chunks, embeddings=embeddings, ids=uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar a busca usando collection.query\n",
    "\n",
    "#query_embedding = model.encode([\"vovó é uma comida\"])\n",
    "query_embedding = model.encode([\"vovó é mentirosa\"])\n",
    "# query_embedding = model.encode([\"lobo é mentiroso\"])\n",
    "results = collection.query(query_embeddings=query_embedding, n_results=1)\n",
    "\n",
    "print(results)\n",
    "\n",
    "# Imprimir os resultados\n",
    "# Fazendo a varredura sobre os campos 'ids', 'distances' e 'documents'\n",
    "for i in range(len(results['ids'][0])):\n",
    "    doc_id = results['ids'][0][i]\n",
    "    distance = results['distances'][0][i]\n",
    "    document = results['documents'][0][i]\n",
    "    \n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(f\"Distância: {distance}\")\n",
    "    print(f\"Documento: {document}\")\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
